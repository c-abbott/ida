---
title: |
  <center> Incomplete Data Analysis </center>
  <center> Assignment 2 </center>
author: "<center> Callum Abbott </center>"
output:
  pdf_document: default
  html_document: default
---

```{r setup, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
knitr::opts_chunk$set(eval = TRUE, echo = TRUE)
library(mice)
library(rjags)
library(JointAI)
library(corrplot)
library(tidyr)
library(dplyr)
```

All code used for this assignment can be found in the following repository [https://github.com/c-abbott/ida] under the folder `assignment-3`.

## Question 1
Consider the `nhanes` dataset in `mice`.

### Question 1a
*(a) What percentage of the cases are incomplete?*

**Solution:**
We observe the NHANES dataset has a total of $25$ cases, $12$ of which are
incomplete. This gives the incomplete case percentage as $48.0\%$.

```{r echo=TRUE}
# Load in dataset
data(nhanes)
# Calculate NA percentage
na_percentage = sum(!complete.cases(nhanes)) / nrow(nhanes) * 100
```

### Question 1b
*(b) Impute the data with `mice` using the defaults with `seed=1`, in step 2 predict*
*`bmi` from `age`, `hyp`, and `chl` by the normal linear regression model, and then pool the*
*results. What are the proportions of variance due to the missing data for each parameter?*
*Which parameters appear to be most affected by the non-response?*

**Solution:**

Let *the proportions of variance due to the missing data for each parameter* be denoted as $\lambda$. 

Mathematically, we specify $\lambda$ to be:
\begin{equation*}
  \lambda = \frac{B + \frac{B}{M}}{V^{\text{MI}}}
\end{equation*}

where $M$ denotes the number of imputed datasets by `mice` (default = 5), $B = \frac{1}{M-1}\sum_{m=1}^M\left(\hat{\theta}^{(m)}-\hat{\theta}^{MI}\right)^2$ denotes the *between-imputation* variance, and $V^{\text{MI}} = \bar{U} + (1 + 1/M)B$ is the *total variance*. Note that $\bar{U} = \frac{1}{M}\sum_{m=1}^M\hat{U}^{(m)}$ is known as the
*within-variance*.

Using the standard MICE procedure - `mice(), with(), pool()` - we yield the following
values for *the proportions of variance due to the missing data for each parameter* (3SF, seed=1):

* `age` = 0.686
* `hyp (positive)` = 0.350
* `chl` = 0.304

We observe that the variable `age` has the highest value of $\lambda$ indicating that
this variable is most affected by the non-response.

```{r}
imps = mice(nhanes, seed=1, printFlag=FALSE) # MI step
fits = with(imps, lm(bmi ~ age + hyp + chl)) # Fitting lm to predict BMI
bmi_ests = pool(fits) # Gather useful summary statistics
bmi_ests[,3][c(1, 3, 10)] # Extracting only the relevant statistics
```

### Question 1c 
*(c) Repeat the analysis for* `seed` $\in {2,3,4,5,6}$. *Do the conclusions remain the same?*

**Solution:**
Repeating an analogous analysis but now varying the seeds to the values given above we
yield different conclusions. For seeds 2, 3 and 6, the `age` variable had the largest
value of $\lambda$ with respective values of 0.403, 0.590 and 0.655.
Meanwhile the `chl` and `hyp` variables had the largest $\lambda$ values
for seeds 4 and 5 with values 0.331 and 0.594 respectively. Other numerical values have not been included for brevity purposes.

This behaviour can be explained by the fact that $48\%$ of cases our are missing in the
NHANES dataset. Therefore, as we adjust the random seed, the proportion of variance due to the missing data can change significantly since it occupies such a large proportion of our
total data and hence leads us to conflicting conclusions.

```{r}
bmi2 = pool(with(mice(nhanes, seed=2, printFlag=FALSE), lm(bmi ~ age + hyp + chl)))
bmi3 = pool(with(mice(nhanes, seed=3, printFlag=FALSE), lm(bmi ~ age + hyp + chl)))
bmi4 = pool(with(mice(nhanes, seed=4, printFlag=FALSE), lm(bmi ~ age + hyp + chl)))
bmi5 = pool(with(mice(nhanes, seed=5, printFlag=FALSE), lm(bmi ~ age + hyp + chl)))
bmi6 = pool(with(mice(nhanes, seed=6, printFlag=FALSE), lm(bmi ~ age + hyp + chl)))
```

### Question 1d
*(d) Repeat the analysis with M = 100 with the same seeds. Would you prefer*
*these analyses over those with M = 5? Explain why.*

**Solution:**
Given that the conclusions derived in 1(c) varied with the random seed, this indicates 
we must increase the value of $M$ (the number of imputed datasets) in order to reduce
the probability of our conclusions being governed by random chance.

We set $M=100$ and repeat the analysis outlined in 1(b) and 1(c). We now find that `age`
is the parameter most affected by the non-response (largest $\lambda$) in 5 of the 6 seeds
with `chl` taking the same stance for seed 3.

Overall, I would favour the conclusions derived from the $M=100$ results since
if we analyze the expression of the *total variance* of the imputed parameter estimates
(in this case `bmi`),

\begin{equation*}
  V^{\text{MI}} = \bar{U} + B + \frac{B}{M}
\end{equation*}

where $\bar{U}$ is the *within-imputation variance* and $B$ is again the 
*between-imputation variance*, we see that increasing $M$ has the effect of reducing
this quantity thus increasing the reliability of estimations. It should be noted that both
$B$ and $\bar{U}$ are also  $\propto \frac{1}{M}$ which further reinforces this notion. 

On the contrary, a larger $M$ results in a lower level of statistical efficiency i.e.
one should be able to arrive at the same statistically significant conclusions
using a lesser amount of computational resources and time. In this context, $M=100$ is
easily handled by most modern machines given the NHANES dataset contains only 25 cases - a low
burden compared to standards of modern datasets.

```{r}
#mbmi1 = pool(with(mice(nhanes, seed=1, m=100, printFlag=FALSE), lm(bmi ~ age + hyp + chl)))
#mbmi2 = pool(with(mice(nhanes, seed=2, m=100, printFlag=FALSE), lm(bmi ~ age + hyp + chl)))
#mbmi3 = pool(with(mice(nhanes, seed=3, m=100, printFlag=FALSE), lm(bmi ~ age + hyp + chl)))
#mbmi4 = pool(with(mice(nhanes, seed=4, m=100, printFlag=FALSE), lm(bmi ~ age + hyp + chl)))
#mbmi5 = pool(with(mice(nhanes, seed=5, m=100, printFlag=FALSE), lm(bmi ~ age + hyp + chl)))
#mbmi6 = pool(with(mice(nhanes, seed=6, m=100, printFlag=FALSE), lm(bmi ~ age + hyp + chl)))
```

# Question 2
*Each of the 100 datasets contained in `dataex2.Rdata` was generated in the* 
*following way*
\begin{equation*}
 y_i | x_i \stackrel{\text{ind.}}{\sim} \mathcal{N}(\beta_0+\beta_1x_i,1), \quad x_i \stackrel{\text{iid}}{\sim} \text{Unif}(-1, 1), \quad \beta_0 = 1, \quad \beta_1 = 3
\end{equation*}
*for* $i = 1,...,100$. *Additionally, some of the responses were set to be missing using a*
*MAR mechanism.* 

*The goal of this exercise is to study the effect that acknowledging/not*
*acknowledging parameter uncertainty when performing step 1 of multiple imputation might*
*have on the coverage of the corresponding confidence intervals. Further suppose that the*
*analysis of interest in step 2 is to fit the regression model that was used to generate the data,*
*i.e., a normal linear regression model where the response is* $y$ *and the covariate is* $x$.

*With the*
*aid of the mice package, calculate the empirical coverage probability of the* $95\%$ *confidence*
*intervals for* $\beta_1$ *under the following two approaches: stochastic regression imputation and*
*the corresponding bootstrap based version. Comment. For both approaches, please consider*
$M = 20$ *and* $\text{seed}=1$

**Solution:**
The R code below compares two methods used to impute missing values in incomplete datasets
through comparing empirical confidence intervals for the $\beta_1$ parameter -
these methods are stochastic regression imputation (SRI) and bootstrap sampling.

We remind the reader how confidence intervals (CIs) of an unknown parameter are interpreted 
in the frequentist paradigm of statistics. Upon collecting a sample of data, 
a $\text{p}\%$ CI can be constructed from this data. If such intervals were constructed
repeatedly from collecting more samples of the data, the $\text{p}\%$ CI will contain
the unknown parameter $\text{p}\%$ of the time.

The R code below hence performs a bootstrap and SRI imputation
method for each of the 100 datasets contained withing `dataex2.Rdata`. Once the
missing data has been imputed, we derive the $95\%$ CIs for each method and
check whether the true value of $\beta_1 = 3$ is contained within
the bootstrap, or SRI, $95\%$ CI. Given the CI interpretation outlined above, one
would expect the true value of $\beta_1$ to be contained within CIs $95\%$ of
the time for both imputation methods.

In reality, we observe this is true for the bootstrap method (`count_boot = 95`)
but not for the SRI method whose CIs only contain the true value of $\beta_1$ 
$88\%$ of the time (`count_sri = 88`). This is because, unlike the bootstrap imputation
method, SRI does not take into consideration the uncertainty surrounding the 
imputed values. More simply put, the SRI method treats the imputed values as if
they were truly observed rather than imputations from missing values.
This treatment is unjustified and hence results in the construction of more narrow, 
overly-confident CIs surrounding $\beta_1$ which are less likely to contain
the true value of $\beta_1$.

```{r}
load('dataex2.Rdata') # Loading in datasets

# Counters to track empirical coverage probability
count_sri = 0
count_boot = 0

# Imputations begin...
for (dataset in 1:2){
  # SRI & Bootstrap MICE methods initialized
  imps_sri = mice(dataex2[,,dataset], m=20, seed=1, printFlag=FALSE, method="norm.nob")
  imps_boot = mice(dataex2[,,dataset], m=20, seed=1, printFlag=FALSE, method="norm.boot")
  # Grab 95% CIs
  stats_sri = summary(pool(with(imps_sri, lm(Y ~ X))), conf.int=TRUE)
  stats_boot = summary(pool(with(imps_boot, lm(Y ~ X))), conf.int=TRUE)
  # Checking whether true value (3) of beta1 is in the CIs
  if (stats_sri$`2.5 %`[2] <= 3 & stats_sri$`97.5 %`[2] >= 3){
    count_sri = count_sri + 1
  }
  if (stats_boot$`2.5 %`[2] <= 3 & stats_boot$`97.5 %`[2] >= 3){
    count_boot = count_boot + 1
  } 
}
```


# Question 3
*Show that for a linear (in the coefficients) regression model, the following two*
*strategies coincide:*

* Method 1: *Computing the predicted values (point estimates) from each fitted model in step 2 and*
   *then pooling them according to Rubin’s rule for point estimates (i.e., averaging the*
    *predicted values across the imputed datasets).*
      
* Method 2: *Pooling the regression coefficients from each fitted model in step 2 using Rubin’s rule*
   *for point estimates and then computing the predicted values afterwards.*
       
**Solution:**

Let us begin by first defining a general linear (in the coefficients) regression
model with a total of $N$ covariates to act as our substantive model in the multiple
imputation process ($\epsilon \sim \mathcal{N}(0, \sigma^2)$).

\begin{align*}
  y &= \sum_{i=0}^N \beta_ix_i + \epsilon \\
  &= \beta_0 + \sum_{i=1}^N \beta_ix_i + \epsilon
\end{align*}

Let us assume that step 1 of the multiple imputation process has been performed
and we are in possession of a total of $M$ imputed datasets. We fit the previously
defined regression model to each of these $M$ datasets yielding a set of predictions, $\mathbf{\hat{y}} = (\hat{y}^{(1)},\hat{y}^{(2)},...,\hat{y}^{(M)})$. Method 1 instructs us to pool these predictions according to Rubin's rule for point estimates yielding,

\begin{align*}
  \tilde{y} &= \frac{1}{M}\sum_{m=1}^M\color{orange}{\hat{y}^{(m)}}\\
  &= \frac{1}{M}\sum_{m=1}^M\color{orange}{\sum_{i=0}^N \beta_i^{(m)}x_i}\\
  &= \color{red}{\sum_{i=0}^Nx_i}\color{blue}{\frac{1}{M}\sum_{m=1}^M\beta_i^{(m)}}\\
  &= \color{red}{\sum_{i=0}^N}\color{blue}{\tilde{\beta}_i}\color{red}{x_i}
\end{align*}

where $\tilde{\beta}_i=\frac{1}{M}\sum_{m=1}^M\beta_i^{(m)}$ - **the pooled regression
coefficients according to Rubin's rules (Method 2)**.

The equations derived above hence indicate that Method 1 and Method 2 are mathematically
equivalent and will lead to the same results and conclusions.

# Question 4 
*The goal of this exercise is to study different ways of using* `mice` *when the analysis model*
*of interest/substantive model involves an interaction term between incomplete variables. The*
*model used to generate the data (available in* `dataex4.Rdata`), *which corresponds to our*
*model of interest in step 2, was the following one:*

\begin{align*}
  y_i &= \beta_0 + \beta_1x_{1i} + \beta_2x_{2i} + \beta_3x_{1i}x_{2i} + \epsilon_i,\\
  x_{1i} &\stackrel{\text{iid}}{\sim} \mathcal{N}(0, 1), \quad x_{2i} \stackrel{\text{iid}}{\sim} \mathcal{N}(1.5, 1), \quad \epsilon_i \stackrel{\text{iid}}{\sim} \mathcal{N}(0,1)
\end{align*}
*for* $i=1,...,1000, \beta_0=1.5, \beta_1=1, \beta_2=2, \beta_3=1$.

*Additionally, missingness was*
*imposed on* $y$ *and* $x_1$ *and so the interaction variable* $x_1x_2$ *also has missing values, although*
*the missingness in this interaction variable is induced by the missing in the covariate* $x_1$.

## Question 4a
*By only imputing the* $y$ *and* $x_1$ *variables in step 1, provide the estimates of*
$\beta_1, \beta_2\; \text{and} \; \beta_3$ *along with 95% confidence intervals. Comment. Note that this approach*
*where the interaction variable is left outside the imputation process and calculated afterwards in the analysis* *model, is known as Impute, then transform.*

**Solution:**

Solution 4a sees us perform the *impute, then transform* method of imputation
where we choose to explicitly impute $x_1$ and $y$ using MICE, and then use the 
imputed $x_1$ values to passively impute the interaction term, $x_1x_2$, in our 
substantive model.

Using a value of $M=50$, `seed=1`  and `maxit=5` we obtain the following estimates and $95\%$
CIs for $\beta_1$, $\beta_2$, and $\beta_3$ (3SF):

* $\beta_1 = 1.41;\quad$        $95\%\text{CI}=[1.22, 1.60]$
* $\beta_2 = 1.97;\quad$        $95\%\text{CI}=[1.86, 2.07]$
* $\beta_3 = 0.75;\quad$       $95\%\text{CI}=[0.642, 0.868]$

Analyzing these results we observe that only the 95% CI associated with $\beta_2$
contains the true value of the parameter ($\beta_2=2$) and a reasonable estimate. 

Meanwhile, we observe that the 95% CIs associated with $\beta_1$ and $\beta_3$ fail
to include the true values of these parameters ($\beta_1=1$, $\beta_3 =1$) and provide
relatively inaccurate estimates. This is unsurprising behaviour since the impute then 
transform method (in general) is known to lead biased estimates (*Hippel, 2009*).


```{r}
load('dataex4.Rdata') # Load data
q4a_imps0 = mice(dataex4, m=50, seed=1, printFlag=FALSE, maxit=0) # Initial MICE
q4a_imps0$predictorMatrix["x2",] = 0 # Explicitly preventing x2 from being imputed

# Running MICE with new predictorMatrix
q4a_imps = mice(dataex4, m=50, seed=1, printFlag=FALSE,
                predictorMatrix=q4a_imps0$predictorMatrix) 
q4a_ests = with(q4a_imps, lm(y ~ x1 + x2 + x1*x2)) # Getting estimates
summary(pool(q4a_ests), conf.int=TRUE)[-1,c(1,2,7,8)] # Extracting relevant statistics
```


## Question 4b
*Now, start by calculating the interaction variable in the incomplete data*
*and append it as a variable to your dataset. Then, use passive imputation to impute the*
*interaction variable. Provide the estimates of* $\beta_1, \beta_2\; \text{and} \; \beta_3$ 
*along with $95\%$ confidence intervals. Comment.*


**Solution:**

Solution 4b sees us add the interaction term to our dataset, $z = x_1x_2$,
and use passive imputation to impute the missing values (maintaining the
deterministic relationship).

Using a value of $M=50$, `seed=1` and `maxit=5` we obtain the following estimates and $95\%$
CIs for $\beta_1$, $\beta_2$, and $\beta_3$ (3SF):

* $\beta_1 = 1.19;\quad$        $95\%\text{CI}=[1.0035, 1.38]$
* $\beta_2 = 2.00;\quad$        $95\%\text{CI}=[1.90, 2.09]$
* $\beta_3 = 0.874;\quad$       $95\%\text{CI}=[0.762, 0.987]$

Using this imputation method we now observe an increase in the accuracy of the estimates
made for all three parameters. In addition, although the 95% CIs for $\beta_1$ and
$\beta_3$ still do not include the true value of these parameter, they
are much closer to doing so than the method implemented in Q4a. Passive imputation,
in this context, has hence resulted in a reduction in the bias of our estimates made by 
our substantive model but not eradicated the problem.

```{r}
# Create interaction variable (z=x1*x2)
dataex4$z = dataex4$x1 * dataex4$x2
# Initial MICE setup
imp_0_pass = mice(dataex4, maxit = 0, seed=1, m=50)
# Specify that z is derived from x1 and x3
meth_pass = imp_0_pass$method
meth_pass["z"] = "~I(x1*x2)"

pred_pass = imp_0_pass$predictorMatrix
pred_pass[c("x1", "x2"), "z"] = 0 # Don't use z to impute x1 and x2
pred_pass["z", "y"] = 0 # Don't use y to impute z

# MI begins...
imp_pass = mice(dataex4, 
                method = meth_pass, 
                predictorMatrix = pred_pass, 
                m = 50, 
                seed = 1, 
                printFlag = FALSE)
imp_pass_ests = with(imp_pass, lm(y ~ x1 + x2 + z))
summary(pool(imp_pass_ests), conf.int=TRUE)[-1,c(1,2,7,8)] 
```

## Question 4c
*Now that you have already appended the interaction variable to the dataset,*
*impute it as it was just another variable (or like any other variable) in the dataset and*
*use this variable for the interaction term in step 2. Provide the estimates of* $\beta_1, \beta_2\; \text{and} \; \beta_3$  *along with 95% confidence intervals. Comment.*

**Solution:**

We now treat the interaction term, $z = x_1x_2$, as if it were *just another variable*
(JAV) meaning that missing values of $z$ are imputed independently of missing
$x_1$ values.

Repeating the procedure performed in 4a and 4b with $M=50$, `seed=1` and `maxit=5`,
we obtain the following estimates and $95\%$ CIs for $\beta_1$, $\beta_2$, and $\beta_3$ (3SF):

* $\beta_1 = 1.0039;\quad$        $95\%\text{CI}=[0.841, 1.17]$
* $\beta_2 = 2.03;\quad$        $95\%\text{CI}=[1.94, 2.11]$
* $\beta_3 = 1.02;\quad$       $95\%\text{CI}=[0.930, 1.105]$

We now observe in the regime of treating the interaction term as just another
variable yields estimates which are accurately to at least 1 decimal place
and all three 95% CIs contain the true parameter values. This is a significant
improvement to what was observed in 4a and 4b.

We can explain this result by the fact that although the substantive model is 
incorrectly specified (regarding the inconsistency in imputed vales) the imputations 
created for all variables do in fact have the correct means and covariances. We
recall that the parameters of our substantive model (the coefficients) depend
only on these imputed values, and hence result in a set of unbiased estimates for the missing
data values.

```{r}
# Just another variable imputation
imps_jav = mice(dataex4, m=50, seed=1, printFlag=FALSE)
ests_jav = with(imps_jav, lm(y ~ x1 + x2 + z))
summary(pool(ests_jav), conf.int=TRUE)[-1,c(1,2,7,8)]
```



## Question 4d
*What is the obvious conceptual drawback of the just another variable approach for* 
*imputing interactions?*

The cost of obtaining unbiased estimates for the parameters of our linear regression
model is that the deterministic relationship for the interaction term, $z=x_1x_2$,
no longer holds.

Re-iterating this point more explicitly, when we impute missing values of $z$ independently
of $x_1$, we remove the deterministic dependence between these two variables and hence
$z \neq x_1x_2$ for the imputed $z$ values.

# Question 5

*The file* `NHANES2.Rdata` *contains a subset of data from the National Health*
*and Nutrition Examination Survey (NHANES), whose goal is to assess the health* 
*and nutritional status of adults and children in the United States.*

*The analysis of interest is the following:*

\begin{equation*}
  \text{wgt} = \beta_0 + \beta_1\text{gender} + \beta_3\text{hgt} + \beta_4\text{WC} + \epsilon, \quad \epsilon \sim \mathcal{N}(0, \sigma^2)
\end{equation*}

*Using multiple imputation and conducting all necessary checks, report your findings.*

```{r include=FALSE}
load("NHANES2.Rdata")
```

### Exploratory Data Analysis (EDA)
We begin our analysis of the `NHANES2` dataset with some exploratory data analysis
(EDA) in order to gain a sense of the data we are working with.

```{r}
head(NHANES2)
dim(NHANES2)
```
We see that the data set consists of 500 cases with 12 variables measured for each case:

* `wgt`: weight in kg,
* `gender`: male vs female,
* `bili`: bilirubin concentration in mg/dL,
* `age`: in years,
* `chol`: total serum cholesterol in mg/dL,
* `HDL`: High-density lipoprotein cholesterol in mg/dL,
* `hgt`: height in metres,
* `educ`: educational status; 5 ordered categories,
* `race`: 5 unordered categories,
* `SBP`: systolic blood pressure in mmHg,
* `hypten`: hypertensive status; binary,
* `WC`: waist circumference in cm

It is now instructive to investigate which variables contain missing values and which
have been fully observed. We perform this analysis using the `md_pattern()` function
provided by the [JointAI](https://nerler.github.io/JointAI/) package. 

The missing data matrix presented below reveals that only `wgt`, `gender`, `age` and `race` 
are fully observed whilst the other 8 variables have the number of missing values
ranging from 1 (`educ`) to 47 (`bili`).

```{r}
JointAI::md_pattern(NHANES2, pattern = FALSE, color = c('#34111b', '#e30f41'))
```

It should be noted that the missing values within the `NHANES2` dataset provided are
represented by `NaN`s rather than the usual `NA`. With the expectation that we 
will perform multiple imputation using the [`mice`](https://cran.r-project.org/web/packages/mice/index.html) package to impute the
previously mentioned missing values, we transform all `NaN`s to `NA`s.

```{r}
NHANES2 = na_if(NHANES2, NaN)
```

We also believe that it is useful to gain a sense of which variables in the `NHANES2` 
dataset are related to one another by analyzing the correlations between variables. A 
nice package for conducting this kind of analysis is [`corrplot`](https://cran.r-project.org/web/packages/corrplot/index.html) which
provides the results shown below.

We observe some unsurprising results such as `gender` being correlated to `hgt`
(height) as well as a strong positive correlation between `wgt` (weight) and `WC`
(waist circumference). More interestingly we observe a significant positive correlation
(>0.5) between `SBP` (systolic blood pressure) and `hypten` (binary hypertensive classification).
Conducting further research into these two variables reveals that an individual 
is classified as hypertensive if their SBP/DBP (diastolic blood pressure) consistently
recorded at 140/90 mmHg.

This finding indicates that the `hypten` variable is in some sense derived from
the `SBP` variable and we should consider the option of using passive imputation 
as our imputation method. However, analysis below reveals there are 61 instances
of a person being positively classified as hypertensive with a `SBP` less than 
140 mmHg. This result suggests that the DBP of an individual plays an important
role in their classification as being hyptertensive and is a variable
we unfortunately have no data for. 

From the above findings we choose to treat the `hypten` variable as if it were
**not** derived from the `SBP` given the lack of data on an individual's DBP.
```{r}
# Converting factor variables to numeric for corrplot()
corr_viz = NHANES2 %>%
  mutate_if(is.factor, as.numeric)

# Visualsing correlations
correlation = cor(corr_viz, method="pearson", use="complete.obs")
corrplot(correlation, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)
```

```{r}
NHANES2[c("SBP", "hypten")] %>%
  filter(SBP < 140) %>%
  count(hypten, name="frequency")
```
We conclude our EDA by finally visualzing all 12 of our variables in order to gain a 
sense of how they are distributed. It seems as though all continuous variables barring `hgt`
are rightly skewed, and hence will be poorly approximated by a normal distribution
indicating that predictive mean matching (PMM) should be the method of choice. Meanwhile,
it seems as though the `hgt` variable could be approximated well by a normal distribution (as
one would expect if the NHANES data collectors strived for a representative population
sample). 

We thus modify the method of imputation for the `hgt` variable from PMM to
`norm` which implements (normal linear) stochastic regression imputation where the regression
coefficients are drawn from the appropriate posteriors to ensure uncertainty is taken
into consideration and proper multiple imputation is conducted. Note that in order
to prevent negative height values being imputed for this variable, we restrict the 
the height imputations to lie between 50cm and 280cm which firmly encompasses all human
heights that have been recorded.


```{r}
par(mar = c(3, 3, 2, 1), mgp = c(2, 0.6, 0))
plot_all(NHANES2, breaks = 30, ncol = 4, fill = '#D10E3B', border = '#460E1B')
```

```{r}
imp0 = mice(NHANES2, maxit = 0) # Initial MICE set up
imp0
# Changing imputation method from pmm for hgt
meth = imp0$method
meth["hgt"] = "norm"
# Restricting support imputation output
post = imp0$post
post["hgt"] <- "imp[[j]][,i] <- squeeze(imp[[j]][,i], c(0.5, 2.8))"
```

We observe in the `predictorMatrix` object that every variable is being used to impute
every other variable which is the desired behavior. We also note the use of `polr` to impute the `educ` variable 
since it requires multi-class classification whilst `logreg` is used for `hypten`
since this variable only requires binary classification. This configuration is now
suitable to begin the multiple imputation process.

### Multiple Imputation
We begin this process by first considering a suitable value for $M$ - the number
of datasets that are to be imputed. We will investigate three values of $M$, specifically,
$M \in \{5, 10, 25\}$. A suitable value of $M$ would be one which has low variance
between random seeds but is not so high that it is unnecessarily computationally expensive.
Random seeds 1 and 2 were used to necessitate this investigation.

We remind the reader the model of interest is the following:
\begin{equation*}
  \text{wgt} = \beta_0 + \beta_1\text{gender} + \beta_3\text{hgt} + \beta_4\text{WC} + \epsilon, \quad \epsilon \sim \mathcal{N}(0, \sigma^2)
\end{equation*}


```{r eval=FALSE, include=FALSE}
# MI for M=5
seed1 = pool(with(mice(NHANES2, methods = meth, post = post,
                            maxit = 20, m = 5, seed = 1, printFlag = FALSE),
                       lm(wgt ~ gender + age + hgt + WC)))

seed2 = pool(with(mice(NHANES2, methods = meth, post = post,
                            maxit = 20, m = 5, seed = 2, printFlag = FALSE),
                       lm(wgt ~ gender + age + hgt + WC)))
summary(seed1, conf.int = TRUE)[c(1,2,6,7,8)]
summary(seed2, conf.int = TRUE)[c(1,2,6,7,8)]

# MI for M=10
seed1_10 = pool(with(mice(NHANES2, methods = meth, post = post,
                                maxit = 20, m = 10, seed = 1, printFlag = FALSE),
                           lm(wgt ~ gender + age + hgt + WC)))
seed2_10 = pool(with(mice(NHANES2, methods = meth, post = post,
                                maxit = 20, m = 10, seed = 2, printFlag = FALSE),
                           lm(wgt ~ gender + age + hgt + WC)))
summary(seed1_10, conf.int = TRUE)[c(1,2,6,7,8)]
summary(seed2_10, conf.int = TRUE)[c(1,2,6,7,8)]

# MI for M=25
seed1_25 = pool(with(mice(NHANES2, methods = meth, post = post,
                                maxit = 20, m = 25, seed = 1, printFlag = FALSE),
                           lm(wgt ~ gender + age + hgt + WC)))
seed2_25 = pool(with(mice(NHANES2, methods = meth, post = post,
                                maxit = 20, m = 25, seed = 2, printFlag = FALSE),
                           lm(wgt ~ gender + age + hgt + WC)))
summary(seed1_25, conf.int = TRUE)[c(1,2,6,7,8)]
summary(seed2_25, conf.int = TRUE)[c(1,2,6,7,8)]
```

The summary statistics above show that the value of $M=10$ strikes a nice compromise
of being both computationally efficient (relevant to $M=25$) and robust to random variation
due to seed choice. 

We hence proceed to perform multiple imputation on the `NHANES2` dataset with `maxit=20`,
`seed=1` and $M=10$. Note that in the code below the `meth` and `post` variables previously
defined were also passed to the `mice()` function and that the `loggedEvents` attribute 
was checked to see if `mice()` detected any problems during the multiple imputation process.

```{r}
imp <- mice(NHANES2, methods = meth, post = post,
            maxit = 20, m = 10, seed = 1, printFlag = FALSE)
imp$loggedEvents
```

No problems were detected during the imputation process hence we check the Monte Carlo
chains to ensure convergence across all 12 variables.

```{r, fig.height=8, fig.width=8}
plot(imp, layout=c(2,8))
```
For the 10 MC chains initialized we observe no clear pattern among any of the chains indicating convergence
for all variables. We note that the standard deviation of the `educ` chain is blank
simply because this variable contains only a single missing value.

It is now instructive to analyze the imputed values provided by `mice()` using box
and density plots for the continuous variables.

```{r, fig.dim=c(6,3)}
bwplot(imp)[c(2,4,5,6,7,8)]
densityplot(imp)
```

The plot above present the box and density plots for the observed (blue) and imputed (red)
datasets for the continuous varaibles. We see that most imputed datasets follow a similar
distribution to their observed counterpart besides `hgt` which chows a clear shift towards
lower values.

From the conditional (`hgt|gender` and `hgt|hypten`) density plot shown below, we 
observe that an individual's gender and hyptensive classification strongly influences 
the imputed datasets. Specifically, `male` and `hypten (positive)` have much more
narrow, concentrated distributions whilst `female` and `hypten (negative)` present much
wider distributions. 

```{r}
densityplot(imp,~hgt|gender, xlim = c(1, 2.2))
densityplot(imp,~hgt|hypten, xlim = c(1, 2.2))
```

To further check whether the imputations for `hgt` variable were appropriate, we create
a `stripplot` which allows the imputed `hgt` values to be compared to the observed values
more explicitly.

Nothing looks suspicious in the `stripplot` hence we can move on with confidence that
our imputations for all continuous variables with missing data are reasonable.

```{r}
stripplot(imp)[6]
```
We now move on to check whether the imputed values for the discrete variables, `educ`
and `hypten`, were appropriate. A [propplot]("https://gist.githubusercontent.com/NErler/0d00375da460dd33839b98faeee2fdab/raw/c6f537ecf80eddcefd94992ec7926aa57d454536/propplot.R") (below) easily demonstrates this by presenting
the proportion of values assigned to each category.

```{r fig.width=6, message=FALSE, warning=FALSE}
require(devtools)
require(reshape2)
require(RColorBrewer)
require(ggplot2)
source_url("https://gist.githubusercontent.com/NErler/0d00375da460dd33839b98faeee2fdab/raw/c6f537ecf80eddcefd94992ec7926aa57d454536/propplot.R")

propplot(imp)
```

We observe an abnormal imputation pattern for the `educ` varaible however this
is **not** a cause for concern since we are only imputing  a single missing
value out of 500 cases. Meanwhile, for the `hypten` variable, we observe
a reasonable amount between imputation variance but not enough such that the 
general distribution of this variable is lost. In summary, all imputations
for variables with missing data have been performed successfully.

### Model Fit Analysis
We conclude this investigation by analyzing the fit of the model of interest

```{r, fig.width=6, fig.height=4}
fit = with(imp, lm(wgt ~ gender + age + hgt + WC))
summary(fit$analyses[[1]])
par(mfrow=c(1,2))
plot(fit$analyses[[1]]$fitted.values, residuals(fit$analyses[[1]]),
xlab = "Fitted values", ylab = "Residuals", main = "Residual Comparison")
qqnorm(rstandard(fit$analyses[[1]]), xlim = c(-4, 4), ylim = c(-6, 6))
qqline(rstandard(fit$analyses[[1]]), col = 2)

summary(fit$analyses[[2]])
par(mfrow=c(1,2))
plot(fit$analyses[[2]]$fitted.values, residuals(fit$analyses[[1]]),
xlab = "Fitted values", ylab = "Residuals", main = "Residual Comparison")
qqnorm(rstandard(fit$analyses[[2]]), xlim = c(-4, 4), ylim = c(-6, 6))
qqline(rstandard(fit$analyses[[2]]), col = 2)
```


```{r echo=FALSE}
pooled_ests <- pool(fit)
df <- data.frame(summary(pooled_ests, conf.int = TRUE)[c(1,2,7,8)])
rownames(df) <- c("$\\beta_0$", "$\\beta_1$","$\\beta_2$", "$\\beta_3$", "$\\beta_4$")
knitr::kable(df, escape = FALSE, digits = 3,
caption = "Final Parameter Estimates")
```

```{r}
pool.r.squared(fit, adjusted = TRUE)
```



## References
Hippel, P.T., 2009. How to Impute Interactions, Squares, and Other Transformed Variables. Sociological methodology, 39(1), pp.265–291.

